[{"C:\\Users\\kevse\\Desktop\\Projects\\FaceDetection\\src\\index.js":"1","C:\\Users\\kevse\\Desktop\\Projects\\FaceDetection\\src\\App.js":"2","C:\\Users\\kevse\\Desktop\\Projects\\FaceDetection\\src\\reportWebVitals.js":"3","C:\\Users\\kevse\\Desktop\\Projects\\FaceDetection\\src\\ObjectDetectionSketch.js":"4"},{"size":500,"mtime":1612124379061,"results":"5","hashOfConfig":"6"},{"size":689,"mtime":1612124510270,"results":"7","hashOfConfig":"6"},{"size":362,"mtime":499162500000,"results":"8","hashOfConfig":"6"},{"size":5184,"mtime":1612124986842,"results":"9","hashOfConfig":"6"},{"filePath":"10","messages":"11","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"12"},"g2tyfs",{"filePath":"13","messages":"14","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"12"},{"filePath":"15","messages":"16","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"12"},{"filePath":"17","messages":"18","errorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"19"},"C:\\Users\\kevse\\Desktop\\Projects\\FaceDetection\\src\\index.js",[],["20","21"],"C:\\Users\\kevse\\Desktop\\Projects\\FaceDetection\\src\\App.js",[],"C:\\Users\\kevse\\Desktop\\Projects\\FaceDetection\\src\\reportWebVitals.js",[],"C:\\Users\\kevse\\Desktop\\Projects\\FaceDetection\\src\\ObjectDetectionSketch.js",["22","23","24","25"],"import * as p5 from 'p5'\r\n//import \"p5/lib/addons/p5.dom\";\r\nimport * as cocoSsd from '@tensorflow-models/coco-ssd';\r\nimport * as faceapi from 'face-api.js';\r\n\r\nconst MODEL_URL = '/models' \r\n// this will pick public folder by default\r\n\r\nexport default function sketch (p) {\r\n    // Variables\r\n    // save current camera image\r\n    let capture = null;\r\n    // save cocossd Model\r\n    let cocossdModel = null;\r\n    // to save the result of cocossd and face-api results\r\n    let cocoDrawings = [];\r\n    let faceDrawings = [];\r\n\r\n    // Custom Function\r\n    // Used to store the result of coco-ssd model\r\n    function showCocoSSDResults(results) {\r\n        const id = capture.id();\r\n        cocoDrawings = results;\r\n    }\r\n    // used to store the result for the face-api.js model\r\n    function showFaceDetectionData(data) {\r\n        faceDrawings = data;\r\n    }\r\n\r\n    // P5.js Functions\r\n    p.setup = async function() {\r\n        await faceapi.loadSsdMobilenetv1Model(MODEL_URL);\r\n        await faceapi.loadAgeGenderModel(MODEL_URL);\r\n        await faceapi.loadFaceExpressionModel(MODEL_URL);\r\n        p.createCanvas(1280, 720);\r\n\r\n        const constraints = {\r\n            video: {\r\n                mandatory: {\r\n                minWidth: 1280,\r\n                minHeight: 720\r\n                },\r\n                optional: [{ maxFrameRate: 10 }]\r\n            },\r\n            audio: false\r\n          };\r\n        capture = p.createCapture(constraints, () => {});\r\n\r\n        capture.id(\"video_element\");\r\n        capture.size(1280, 720);\r\n        capture.hide(); // this is require as we don't want to show the deafault video input\r\n\r\n        cocoSsd.load().then((model) => {\r\n            try {\r\n                cocossdModel = model;\r\n            } catch(e) {\r\n                console.log(e);\r\n            }\r\n          }).catch((e) => {\r\n              console.log(\"Error occured : \", e);\r\n          });\r\n    }\r\n\r\n\r\n    p.draw = function() {\r\n        p.background(255);\r\n        p.image(capture, 0, 0);     \r\n        p.fill(0,0,0,0);\r\n\r\n        cocoDrawings.map((drawing) => {\r\n            if (drawing) {\r\n                p.textSize(20);\r\n                p.strokeWeight(1);\r\n                const textX = drawing.bbox[0]+drawing.bbox[2];\r\n                const textY = drawing.bbox[1]+drawing.bbox[3];\r\n              \r\n                const confidenetext = \"Confidence: \"+ drawing.score.toFixed(1);\r\n                const textWidth = p.textWidth(confidenetext);\r\n              \r\n                const itemTextWidth = p.textWidth(drawing.class);\r\n                p.text(drawing.class, textX-itemTextWidth-10, textY-50);\r\n          p.text(confidenetext, textX-textWidth-10, textY-10);\r\n                p.strokeWeight(4);\r\n                p.stroke('rgb(100%,100%,100%)');\r\n                p.rect(drawing.bbox[0], drawing.bbox[1], drawing.bbox[2], drawing.bbox[3]);\r\n            }\r\n          });\r\n\r\n\r\n        faceDrawings.map((drawing) => {\r\n            if (drawing) {\r\n                p.textSize(15);\r\n                p.strokeWeight(1);\r\n                const textX = drawing.detection.box._x+drawing.detection.box._width;\r\n                const textY = drawing.detection.box._y+drawing.detection.box._height;\r\n                \r\n                const confidenetext = \"Gender: \"+ drawing.gender;\r\n                const textWidth = p.textWidth(confidenetext);\r\n                p.text(confidenetext, textX-textWidth, textY-60);\r\n                const agetext = \"Age: \"+ drawing.age.toFixed(0);\r\n                const ageTextWidth = p.textWidth(agetext);\r\n                p.text(agetext, textX-ageTextWidth, textY-30);\r\n                const copiedExpression = drawing.expressions;\r\n                const expressions = Object.keys(copiedExpression).map((key) => {\r\n                    const value = copiedExpression[key];\r\n                    return value;\r\n                })\r\n                const max = Math.max(...expressions);\r\n                \r\n                const expression_value =    Object.keys(copiedExpression).filter((key) => {\r\n                    return copiedExpression[key] === max; \r\n                })[0];\r\n                const expressiontext = \"Mood: \"+ expression_value;\r\n                const expressionWidth = p.textWidth(expressiontext);\r\n                p.text(expressiontext, textX-expressionWidth, textY-10);\r\n                \r\n                p.strokeWeight(4);\r\n                p.stroke('rgb(100%,0%,10%)');\r\n                p.rect(drawing.detection.box._x, drawing.detection.box._y, drawing.detection.box._width, drawing.detection.box._height);      \r\n            \r\n            }\r\n        });\r\n\r\n\r\n        faceapi.detectAllFaces(capture.id())\r\n            .withAgeAndGender()\r\n            .withFaceExpressions()\r\n            .then((data) => {\r\n                showFaceDetectionData(data);\r\n            });\r\n\r\n        if(capture.loadedmetadata) {\r\n            if (cocossdModel) {\r\n                cocossdModel\r\n                .detect(document.getElementById(\"video_element\"))\r\n                .then(showCocoSSDResults)\r\n                .catch((e) => {\r\n                    console.log(\"Exception : \", e);\r\n                });\r\n            }\r\n        }\r\n\r\n    }\r\n}",{"ruleId":"26","replacedBy":"27"},{"ruleId":"28","replacedBy":"29"},{"ruleId":"30","severity":1,"message":"31","line":1,"column":13,"nodeType":"32","messageId":"33","endLine":1,"endColumn":15},{"ruleId":"30","severity":1,"message":"34","line":22,"column":15,"nodeType":"32","messageId":"33","endLine":22,"endColumn":17},{"ruleId":"35","severity":1,"message":"36","line":70,"column":36,"nodeType":"37","messageId":"38","endLine":70,"endColumn":38},{"ruleId":"35","severity":1,"message":"36","line":90,"column":36,"nodeType":"37","messageId":"38","endLine":90,"endColumn":38},"no-native-reassign",["39"],"no-negated-in-lhs",["40"],"no-unused-vars","'p5' is defined but never used.","Identifier","unusedVar","'id' is assigned a value but never used.","array-callback-return","Array.prototype.map() expects a return value from arrow function.","ArrowFunctionExpression","expectedInside","no-global-assign","no-unsafe-negation"]